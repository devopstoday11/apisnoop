#+TITLE: Endpoint Coverage
#+AUTHOR: Zach Mandeville

* Ticket
  https://gitlab.ii.coop/apisnoop/apisnoop_v3/issues/50
  #+BEGIN_QUOTE
This is the standard info we use to generate the classic APISnoop sunburst.  This should be available, then, as a query we can make in the raiinbow frontend, to build out the sunburst again.
  #+END_QUOTE
  
  So we are not making the sunburst yet, this can just be a table that is showing operationID, hits, test_hits, and conformance_hits.
* Definitions
  - unhit :: operation_id is present in the corresponding swagger.json for that audit, but is not present in any of the audit logs.
  - hit :: operation_id is present in the audit log. 
  - test_hit :: operation_id is present in the audit log, and includes events with a useragent that starts with ~e2e.test~
  - other_hits :: appearances of operation_id in the event where useragent does not start with ~e2e.test~
  - conformance_hit :: same as test_hit, but event includes useragents whose test name includes ~[Conformance]~
  - total_hits :: how many times the operation_id appears in the audit_event.  test_hit + other_hits should add up to total_hits.

If an operation_id is present in the audit event, then it is by definition hit.  If we want to show the unhit operation_id's (which we do), then we will need to do a union with our api_operation table.
[[file:~/ii/apisnoop/org/tables_and_views.org::*450:%20PodSpec%20Field%20Summary%20View][450: PodSpec Field Summary View]] is a good example of how to do this.
* Process
** Double check that both audit_events loaded
   We should, as part of getting the db up, have two audit events loaded.  I did a quick check at the start and found only one.
   #+Check for both audit events
   #+BEGIN_SRC sql-mode
     SELECT
       bucket,
       job
       -- count(*) filter (where useragent like 'e2e.test%') as test_hits
       FROM
           audit_event
       GROUP BY bucket, job;
   #+END_SRC
   
   So I ran the load_audit_events function for the one missing, refreshing our two materialized views that spring from it.
   #+BEGIN_SRC sql-mode :results silent
  select * from load_audit_events('ci-kubernetes-e2e-gci-gce', '1173412183980118017');
   REFRESH MATERIALIZED VIEW kind_field_path_material;
   REFRESH MATERIALIZED VIEW podspec_field_coverage_material;
   #+END_SRC


   I am unsure why one would not be there, when it was there yesterday.  We should double check that both exist as soon as the db is up, otherwise our population migration may not be working as we expect.
** Check how to count numbers for two different bucket/jobs
   to start, we want to just give an overall sum of numbers where the query is run once but divided into two bucket/jobs.  We can compare these numbers to our apisnoop to make sure they are the same.  From here we can git more specific with the columns.
   
   #+NAME: test, conf, other for bucket and job
   #+BEGIN_SRC sql-mode
     SELECT DISTINCT
       bucket,
       job,
       operation_id,
       count(*) filter (where useragent like 'e2e.test%') as test_hits,
       count(*) filter (where useragent not like 'e2e.test%') as other_hits,
       count(*) filter (where useragent is null) as null_user,
       count(*) as total_hits
       FROM
           audit_event 
       GROUP BY bucket, job, operation_id
       LIMIT 20;
   #+END_SRC

   #+RESULTS: test, conf, other for bucket and job
   #+begin_src sql-mode
             bucket           |         job         |                        operation_id                         | test_hits | other_hits | null_user | total_hits 
   ---------------------------+---------------------+-------------------------------------------------------------+-----------+------------+-----------+------------
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | connectCoreV1GetNamespacedPodExec                           |         0 |          0 |         2 |          2
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | connectCoreV1GetNamespacedPodPortforward                    |         0 |          0 |         4 |          4
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | connectCoreV1PostNamespacedPodAttach                        |         0 |         12 |         0 |         12
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | connectCoreV1PostNamespacedPodExec                          |         0 |       2655 |         0 |       2655
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | connectCoreV1PostNamespacedPodPortforward                   |         0 |         14 |         0 |         14
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | createAdmissionregistrationV1MutatingWebhookConfiguration   |        18 |          0 |         0 |         18
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | createAdmissionregistrationV1ValidatingWebhookConfiguration |        22 |          0 |         0 |         22
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | createApiextensionsV1beta1CustomResourceDefinition          |         0 |         70 |         0 |         70
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | createApiextensionsV1CustomResourceDefinition               |        41 |          0 |         0 |         41
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | createApiregistrationV1APIService                           |         1 |         89 |         0 |         90
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | createAppsV1NamespacedControllerRevision                    |         0 |        190 |         0 |        190
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | createAppsV1NamespacedDaemonSet                             |        10 |          2 |         0 |         12
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | createAppsV1NamespacedDeployment                            |        33 |         14 |         0 |         47
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | createAppsV1NamespacedReplicaSet                            |        17 |        104 |         0 |        121
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | createAppsV1NamespacedStatefulSet                           |       174 |          0 |         0 |        174
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | createAuthenticationV1TokenReview                           |         1 |          0 |         0 |          1
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | createAuthorizationV1beta1SubjectAccessReview               |         0 |        341 |         0 |        341
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | createAuthorizationV1SelfSubjectAccessReview                |         1 |          0 |         0 |          1
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | createAuthorizationV1SubjectAccessReview                    |       852 |          0 |         0 |        852
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | createBatchV1beta1NamespacedCronJob                         |         8 |          1 |         0 |          9
   (20 rows)

   #+end_src
   We can double check this math by lessing test_hits and null_hits from total_hits. The value should equal other_hits.
   #+BEGIN_SRC python :results output
     print("should equal 217840:  ", 322676 - 104828 - 8)
     print("should equal 220338:  ", 325712 - 105366 - 8)
   #+END_SRC

   Sweet!  And the count is already distinguishing the different bucket jobs as we want.
   
** Build out Count for test hits and conformance hits
   
   I built out the initial query, and then started to filter to endpoints grabbed from apisnoop.
   Everything matched in the two buckets except for this readCoreV1NamespacedPod.  
   #+NAME: Count of Test Hits and Conformance Hits
   #+BEGIN_SRC  sql-mode
     SELECT DISTINCT
       ae.bucket,
       ae.job,
       ae.operation_id,
       count(*) filter (where useragent like 'e2e.test%') as test_hits,
       count(*) filter (where useragent like 'e2e.test%' AND useragent like '%[Conformance]%') as conf_hits,
       count(*) filter (where useragent not like 'e2e.test%') as other_hits,
       count(*) filter (where useragent is null) as null_user,
       count(*) as total_hits,
       bjs.job_timestamp::date as date
       FROM
           audit_event  ae
       NATURAL JOIN bucket_job_swagger bjs
       WHERE (operation_id = 'readCoreV1NamespacedPod')
       GROUP BY bucket, job, operation_id, bjs.job_timestamp
       LIMIT 50;
   #+END_SRC

   #+RESULTS: Count of Test Hits and Conformance Hits
   #+begin_src sql-mode
             bucket           |         job         |      operation_id       | test_hits | conf_hits | other_hits | null_user | total_hits |    date    
   ---------------------------+---------------------+-------------------------+-----------+-----------+------------+-----------+------------+------------
    ci-kubernetes-e2e-gci-gce | 1165794879855398916 | readCoreV1NamespacedPod |      9301 |      2463 |       9373 |         0 |      18674 | 2019-08-26
    ci-kubernetes-e2e-gci-gce | 1173412183980118017 | readCoreV1NamespacedPod |      9938 |      2560 |      10229 |         0 |      20167 | 2019-09-16
    ci-kubernetes-e2e-gci-gce | 1178464478988079104 | readCoreV1NamespacedPod |     10089 |      2908 |      10124 |         0 |      20213 | 2019-09-30
    ci-kubernetes-e2e-gci-gce | 1181584183475048448 | readCoreV1NamespacedPod |     12354 |      3296 |      10856 |         0 |      23210 | 2019-10-08
   (4 rows)

   #+end_src
   
   I took a look at the useragents that are coutning as conformance, to see why the number might be off by several hundred hits.  A quick scan (there are 300+ results) didn't show any glaring weirdness.  So I started to do a find/replace on keywords that stood out.  I saw that tests around Garbage collectors are in these results, but they are not in our apisnoop.cncf.io results of tests.  This is a bit too manual to dive deeper into now, but it is easier to follow,a nd therefore trust, the results here.  I am going to say they are good.
   
   #+BEGIN_SRC sql-mode
     select DISTINCT
       split_part(useragent, '--', 2) as test
       from audit_event
      WHERE (useragent like 'e2e.test%' AND useragent like '%[Conformance]%')
            -- AND (operation_id = 'readCoreV1NamespacedPod');
      and job = '1165794879855398916'
     EXCEPT
     select DISTINCT
       split_part(useragent, '--', 2) as test
       from audit_event
      WHERE (useragent like 'e2e.test%' AND useragent like '%[Conformance]%')
            -- AND (operation_id = 'readCoreV1NamespacedPod');
      and job = '1173412183980118017'
      ;
   #+END_SRC

   #+RESULTS:
   #+begin_src sql-mode
                                                                                  test                                                                                
   -------------------------------------------------------------------------------------------------------------------------------------------------------------------
     [sig-api-machinery] CustomResourceDefinition resources Simple CustomResourceDefinition creating/deleting custom resource definition objects works  [Conformance]
   (1 row)

   #+end_src

** Build out Count for No Hits Too
   I am wondering if I could just do a left join on the api_operation table, but where we do a where clause on tests so that if it's null we mark it as 0.
   
   #+NAME: Collecting Unhits
   #+BEGIN_SRC sql-mode
     CREATE OR REPLACE VIEW "public"."endpoint_coverage" AS
      SELECT DISTINCT
        bjs.job_timestamp::date as date,
        ao.bucket as bucket,
        ao.job as job,
        ao.operation_id as operation_id,
        ao.level,
        ao.category,
        ao.k8s_group as group,
        ao.k8s_kind as kind,
        ao.k8s_version as version,
        count(*) filter (where ae.useragent like 'e2e.test%') as test_hits,
        count(*) filter (where ae.useragent like 'e2e.test%' AND useragent like '%[Conformance]%') as conf_hits,
        count(*) filter (where ae.useragent not like 'e2e.test%') as other_hits,
        count(ae.useragent) total_hits
        FROM api_operation ao
               LEFT JOIN audit_event ae ON (ao.operation_id = ae.operation_id AND ao.bucket = ae.bucket AND ao.job = ae.job)
               LEFT JOIN bucket_job_swagger bjs ON (ao.bucket = bjs.bucket AND ao.job = bjs.job)
        where not ao.deprecated
        GROUP BY ao.operation_id, ao.bucket, ao.job, date, ao.level, ao.category, ao.k8s_group, ao.k8s_kind, ao.k8s_version;
   #+END_SRC

   #+RESULTS: Collecting Unhits
   #+begin_src sql-mode
   CREATE VIEW
   #+end_src

   I can test this against some endpoints that I know have tests and those that I know are not hit.
   
   #+BEGIN_SRC sql-mode
     select date, operation_id, test_hits, conf_hits
      from endpoint_coverage
      where (operation_id = 'patchCoreV1NamespacedEndpoints')
      OR (operation_id = 'replaceCoreV1NamespacedConfigMap')
      OR (operation_id = 'createCoreV1Namespace')
      OR (operation_id = 'readCoreV1NamespacedService')
      OR (operation_id = 'readCoreV1NamespacedResourceQuota')
      OR (operation_id = 'readCoreV1NamespacedEvent')
      OR (operation_id = 'listCoreV1EventForAllNamespaces')
      OR (operation_id = 'readCoreV1Namespace')
      ORDER BY operation_id, date;
   #+END_SRC

   #+RESULTS:
   #+begin_src sql-mode
       date    |           operation_id            | test_hits | conf_hits 
   ------------+-----------------------------------+-----------+-----------
    2019-09-16 | createCoreV1Namespace             |      1706 |       558
    2019-09-30 | createCoreV1Namespace             |      1712 |       564
    2019-09-16 | listCoreV1EventForAllNamespaces   |         0 |         0
    2019-09-30 | listCoreV1EventForAllNamespaces   |         0 |         0
    2019-09-16 | patchCoreV1NamespacedEndpoints    |         0 |         0
    2019-09-30 | patchCoreV1NamespacedEndpoints    |         0 |         0
    2019-09-16 | readCoreV1Namespace               |      5771 |      1984
    2019-09-30 | readCoreV1Namespace               |      5863 |      2012
    2019-09-16 | readCoreV1NamespacedEvent         |         0 |         0
    2019-09-30 | readCoreV1NamespacedEvent         |         0 |         0
    2019-09-16 | readCoreV1NamespacedResourceQuota |        55 |        41
    2019-09-30 | readCoreV1NamespacedResourceQuota |        57 |        40
    2019-09-16 | readCoreV1NamespacedService       |       361 |       260
    2019-09-30 | readCoreV1NamespacedService       |       361 |       260
    2019-09-16 | replaceCoreV1NamespacedConfigMap  |       148 |       136
    2019-09-30 | replaceCoreV1NamespacedConfigMap  |       144 |       132
   (16 rows)

   #+end_src
   
  All of them match except the ~readCoreV1NamespacedService~ which has far more than the others.  Because of the 
** Grab a summary of percent tested per date
   This is a rough version of getting the summaries, but the sql query is executing slowly.  It might be due to there being no indexes on our endpiont coverage, or we are doing too many counts.
  #+BEGIN_SRC sql-mode
    EXPLAIN select
      date,
      COUNT(operation_id) as total_endpoints,
      COUNT(*) filter(WHERE test_hits > 0) as test_hits,
      COUNT(*) filter(WHERE conf_hits > 0) as conf_hits,
      ROUND(((count(*) filter(WHERE test_hits > 0)) * 100 )::numeric / count(*), 2) as percent_tested,
      ROUND(((count(*) filter(WHERE conf_hits > 0)) * 100 )::numeric / count(*), 2) as percent_conf_tested
      from endpoint_coverage 
      where level = 'stable'
      group by date
      ;
  #+END_SRC

  #+RESULTS:
  #+begin_src sql-mode
                                                                                                                                                                                                                                                                                                                                QUERY PLAN                                                                                                                                                                                                                                                                                                                              
  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
   GroupAggregate  (cost=554721.32..564675.32 rows=200 width=92)
     Group Key: ((bjs.job_timestamp)::date)
     ->  Unique  (cost=554721.32..559180.32 rows=137200 width=166)
           ->  Sort  (cost=554721.32..555064.32 rows=137200 width=166)
                 Sort Key: ((bjs.job_timestamp)::date), api_operation_material.bucket, api_operation_material.job, api_operation_material.operation_id, api_operation_material.category, api_operation_material.k8s_group, api_operation_material.k8s_kind, api_operation_material.k8s_version, (count(*) FILTER (WHERE ((raw.data ->> 'userAgent'::text) ~~ 'e2e.test%'::text))), (count(*) FILTER (WHERE (((raw.data ->> 'userAgent'::text) ~~ 'e2e.test%'::text) AND ((raw.data ->> 'userAgent'::text) ~~ '%[Conformance]%'::text)))), (count(*) FILTER (WHERE ((raw.data ->> 'userAgent'::text) !~~ 'e2e.test%'::text))), (count((raw.data ->> 'userAgent'::text)))
                 ->  GroupAggregate  (cost=512361.90..531758.10 rows=137200 width=166)
                       Group Key: api_operation_material.operation_id, api_operation_material.bucket, api_operation_material.job, ((bjs.job_timestamp)::date), api_operation_material.level, api_operation_material.category, api_operation_material.k8s_group, api_operation_material.k8s_kind, api_operation_material.k8s_version
                       ->  Sort  (cost=512361.90..513130.65 rows=307499 width=1263)
                             Sort Key: api_operation_material.operation_id, api_operation_material.bucket, api_operation_material.job, ((bjs.job_timestamp)::date), api_operation_material.category, api_operation_material.k8s_group, api_operation_material.k8s_kind, api_operation_material.k8s_version
                             ->  Hash Left Join  (cost=1176.56..145897.03 rows=307499 width=1263)
                                   Hash Cond: (raw.operation_id = api_operation_parameter_material.param_op)
                                   ->  Hash Left Join  (cost=380.94..133392.40 rows=224722 width=1300)
                                         Hash Cond: ((api_operation_material.bucket = bjs.bucket) AND (api_operation_material.job = bjs.job))
                                         ->  Hash Right Join  (cost=365.94..132197.53 rows=224722 width=1292)
                                               Hash Cond: ((raw.operation_id = api_operation_material.operation_id) AND (raw.bucket = api_operation_material.bucket) AND (raw.job = api_operation_material.job))
                                               ->  Seq Scan on raw_audit_event raw  (cost=0.00..119844.35 rows=649335 width=1208)
                                               ->  Hash  (cost=351.15..351.15 rows=845 width=130)
                                                     ->  Seq Scan on api_operation_material  (cost=0.00..351.15 rows=845 width=130)
                                                           Filter: ((NOT deprecated) AND (level = 'stable'::text))
                                         ->  Hash  (cost=12.00..12.00 rows=200 width=72)
                                               ->  Seq Scan on bucket_job_swagger bjs  (cost=0.00..12.00 rows=200 width=72)
                                   ->  Hash  (cost=782.45..782.45 rows=1054 width=43)
                                         ->  Seq Scan on api_operation_parameter_material  (cost=0.00..782.45 rows=1054 width=43)
                                               Filter: (param_name = 'body'::text)
   JIT:
     Functions: 49
     Options: Inlining true, Optimization true, Expressions true, Deforming true
  (27 rows)

  #+end_src
  
  Regardless, it gives us the numbers we want...though it's going to be lower than our last report due to there being more endpoints in the swagger than we've been accounting for (1126 compared to 900).
  
  #+NAME: Testing Percentages with Timestamp
  #+BEGIN_SRC sql-mode
    SELECT
      date,
      COUNT(operation_id) as total_endpoints,
      COUNT(*) filter(WHERE test_hits > 0) as test_hits,
      COUNT(*) filter(WHERE conf_hits > 0) as conf_hits,
      ROUND(((count(*) filter(WHERE test_hits > 0)) * 100 )::numeric / count(*), 2) as percent_tested,
      ROUND(((count(*) filter(WHERE conf_hits > 0)) * 100 )::numeric / count(*), 2) as percent_conf_tested
      FROM endpoint_coverage GROUP BY date;
  #+END_SRC

  #+RESULTS: Testing Percentages with Timestamp
  #+begin_src sql-mode
      date    | total_endpoints | test_hits | conf_hits | percent_tested | percent_conf_tested 
  ------------+-----------------+-----------+-----------+----------------+---------------------
   2019-08-26 |             900 |       221 |       129 |          24.56 |               14.33
   2019-09-16 |             910 |       224 |       147 |          24.62 |               16.15
   2019-09-30 |             910 |       224 |       153 |          24.62 |               16.81
   2019-10-08 |             910 |       213 |       137 |          23.41 |               15.05
  (4 rows)

  #+end_src
  
  #+NAME: Testing Percentages with Timestamp Stable Core
  #+BEGIN_SRC sql-mode
    SELECT
      date,
      COUNT(1) as total_endpoints,
      COUNT(1) filter(WHERE test_hits > 0) as test_hits,
      COUNT(1) filter(WHERE conf_hits > 0) as conf_hits,
      ROUND(((count(*) filter(WHERE test_hits > 0)) * 100 )::numeric / count(*), 2) as percent_tested,
      ROUND(((count(*) filter(WHERE conf_hits > 0)) * 100 )::numeric / count(*), 2) as percent_conf_tested
      FROM endpoint_coverage 
     WHERE (level = 'stable') -- AND (category = 'core')
     GROUP BY date;
  #+END_SRC

  #+RESULTS: Testing Percentages with Timestamp Stable Core
  #+begin_src sql-mode
      date    | total_endpoints | test_hits | conf_hits | percent_tested | percent_conf_tested 
  ------------+-----------------+-----------+-----------+----------------+---------------------
   2019-08-26 |             429 |       169 |       100 |          39.39 |               23.31
   2019-09-16 |             430 |       171 |       118 |          39.77 |               27.44
   2019-09-30 |             430 |       171 |       124 |          39.77 |               28.84
   2019-10-08 |             430 |       165 |       114 |          38.37 |               26.51
  (4 rows)

  #+end_src
  
  While the percentages are smaller than apisnoop, the ratios and lack of change from 9/16 to 9/30 track with apisnoop.  I think these percentages are correct, just affected by an updated swagger.json

* Conclusion
  We successfully created an endpoint view and a status view.  The numbers for the most part match to our website.  Where they don't, it is because our new db is capturing _more_ information.  This is most telling in our overall stats, where we are using newer swagger.jsons with more endpoints, so our total percentages are lower (though the ratios and rate of change are consistent with the site.)
* Next Steps
 - Move these views into our meta.org, as they are useful to have around.
 - build indexes for endpoint coverage to improve performance
 - investigate analyzing and explaining our queries to fine-tune them (perhaps using less count statements)
* Footnotes
** Connect to Database
    If you already have your db and hasura endpoint up and running:
 - [ ] Connect to your postgres db from within this file
   You'll want execute this code block by moving your cursor within and typing =,,=
  
   #+NAME: Connect org to postgres
   #+BEGIN_SRC emacs-lisp :results silent
     (sql-connect "apisnoop" (concat "*SQL: postgres:data*"))
   #+END_SRC

 - [ ] Test your connection works
   You can run this sql block, and it see a message in your minbuffer like:
   : You are connected to database "apisnoop" as user "apisnoop" on host "localhost" at port "10041".
   
   #+NAME: Test Connection
   #+BEGIN_SRC sql-mode :results silent
   \conninfo
   #+END_SRC
